# -*- coding: utf-8 -*-
"""otpensource_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14glPthiXvqNdq8pXLMkDcfkX1kXB1Y3o
"""

# 📌 1️⃣ MongoDB 연결 및 기본 설정
import datetime
import numpy as np
import torch
from pymongo import MongoClient
from bson import ObjectId
from sklearn.metrics.pairwise import cosine_similarity
from PIL import Image
from io import BytesIO
import base64

# ✅ MongoDB Atlas 연결
MONGO_URI = "MONGO_URI"
client = MongoClient(MONGO_URI)
db = client["otpensource"]
clothes_col = db["clothes"]

# ✅ Base64 → PIL 이미지 변환 함수
def decode_base64_to_image(image_base64: str):
    """Base64 문자열을 PIL 이미지로 변환"""
    try:
        image_data = base64.b64decode(image_base64)
        image = Image.open(BytesIO(image_data)).convert("RGB")
        return image
    except Exception as e:
        print(f"❌ 이미지 디코딩 오류: {e}")
        return None

print("✅ MongoDB 및 Base64 이미지 처리 설정 완료!")

import torch
from transformers import CLIPModel, CLIPProcessor

# ✅ CLIP 모델 설정
model_name = "openai/clip-vit-base-patch32"
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"[INFO] Loading CLIP model: {model_name} on device={device}")

clip_model = CLIPModel.from_pretrained(model_name).to(device)
clip_processor = CLIPProcessor.from_pretrained(model_name)

# ✅ PIL 이미지를 CLIP 임베딩 벡터로 변환
def get_clip_image_embedding(image: Image.Image):
    """PIL 이미지를 CLIP 모델 임베딩으로 변환"""
    try:
        inputs = clip_processor(images=image, return_tensors="pt").to(device)
        with torch.no_grad():
            outputs = clip_model.get_image_features(**inputs)
        embedding = outputs[0].cpu().numpy()
        return embedding.tolist()  # 리스트 형태로 반환
    except Exception as e:
        print(f"❌ CLIP 임베딩 오류: {e}")
        return None

print("✅ CLIP 모델 및 임베딩 함수 로드 완료!")

# ✅ 기존 의류 데이터와 비교 (Cosine Similarity)
def find_most_similar_embedding(new_embedding, threshold=0.9):
    """
    새로운 이미지 임베딩과 DB의 기존 데이터 비교하여 가장 유사한 항목 찾기
    - threshold 이상의 유사도를 가진 경우 해당 문서 반환
    - 없을 경우 None 반환
    """
    try:
        # DB에서 저장된 모든 의류 데이터 가져오기
        docs = list(clothes_col.find({"embedding_vector": {"$exists": True, "$ne": None}}))

        if not docs:
            return None, 0.0  # 저장된 데이터가 없는 경우

        embedding_list = [np.array(doc["embedding_vector"], dtype=np.float32) for doc in docs]
        embedding_matrix = np.stack(embedding_list, axis=0)

        new_emb = np.array(new_embedding, dtype=np.float32).reshape(1, -1)
        sim_scores = cosine_similarity(new_emb, embedding_matrix)[0]

        # 가장 유사한 데이터 찾기
        max_idx = np.argmax(sim_scores)
        max_sim = float(sim_scores[max_idx])
        best_doc = docs[max_idx]

        return (best_doc, max_sim) if max_sim >= threshold else (None, max_sim)

    except Exception as e:
        print(f"❌ 유사도 비교 오류: {e}")
        return None, 0.0

print("✅ 유사도 비교 함수 로드 완료!")

# ✅ 새로운 의류 데이터 저장
def create_new_clothing(item_data):
    """
    새로운 의류 데이터를 MongoDB에 저장
    - 생성 날짜 및 업데이트 날짜 추가
    - 착용 횟수(count) 초기값 1 설정
    """
    try:
        now = datetime.datetime.now(datetime.timezone.utc)
        item_data["created_at"] = now
        item_data["updated_at"] = now
        item_data["count"] = 1  # 착용 횟수 초기값 설정

        result = clothes_col.insert_one(item_data)
        return str(result.inserted_id)

    except Exception as e:
        print(f"❌ 데이터 저장 오류: {e}")
        return None


# ✅ 기존 의류 데이터를 조회하고, 필요하면 업데이트 수행
def read_clothing_item(doc_id: str):
    """
    - `doc_id`를 받아 해당 의류 데이터를 조회 (업데이트 X)
    - ObjectId → 문자열 변환 후 반환
    """
    try:
        existing_doc = clothes_col.find_one({"_id": ObjectId(doc_id)})

        if not existing_doc:
            return {"error": "해당 ID의 의류 데이터를 찾을 수 없습니다."}

        existing_doc["_id"] = str(existing_doc["_id"])  # ObjectId → 문자열 변환
        return existing_doc  # 조회된 데이터 반환

    except Exception as e:
        print(f"❌ 데이터 조회 오류: {e}")
        return {"error": str(e)}


def update_clothing_item(doc_id: str, update_data: dict):
    """
    - `doc_id`를 받아 해당 의류 데이터를 업데이트
    - `count` 필드를 증가시키고, `updated_at` 변경
    """
    try:
        existing_doc = clothes_col.find_one({"_id": ObjectId(doc_id)})

        if not existing_doc:
            return {"error": "해당 ID의 의류 데이터를 찾을 수 없습니다."}

        new_count = existing_doc.get("count", 0) + 1  # 착용 횟수 증가
        update_data["count"] = new_count
        update_data["updated_at"] = datetime.datetime.now(datetime.timezone.utc)

        clothes_col.update_one({"_id": ObjectId(doc_id)}, {"$set": update_data})

        return {"message": "데이터가 업데이트되었습니다.", "doc_id": doc_id, "updated_data": update_data}

    except Exception as e:
        print(f"❌ 데이터 업데이트 오류: {e}")
        return {"error": str(e)}


def delete_clothing_item(doc_id: str):
    """
    - `doc_id`를 받아 해당 의류 데이터를 삭제
    - 삭제 성공 여부를 반환
    """
    try:
        # 먼저 데이터가 존재하는지 확인
        existing_doc = clothes_col.find_one({"_id": ObjectId(doc_id)})

        if not existing_doc:
            return {"error": "해당 ID의 의류 데이터를 찾을 수 없습니다."}

        # 데이터 삭제 수행
        clothes_col.delete_one({"_id": ObjectId(doc_id)})

        return {"message": "의류 데이터가 성공적으로 삭제되었습니다.", "doc_id": doc_id}

    except Exception as e:
        print(f"❌ 데이터 삭제 오류: {e}")
        return {"error": str(e)}


print("✅ 의류 데이터 관리 함수 로드 완료!")

import torch
from transformers import AutoProcessor, MllamaForConditionalGeneration

# Determine the device (GPU if available, else CPU)
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load the model and processor
model_name = """hateslopacademy/otpensource-vision-lora"""
model = MllamaForConditionalGeneration.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map='cuda:0'
)

# Move the model to the appropriate device (GPU if available)
model.to(device)
processor = AutoProcessor.from_pretrained("hateslopacademy/otpensource-vision")
# VRAM을 많이 먹을 경우 아래 코드 실행
# model.eval()

def run_ai_model(image):
    """
    - AI 모델을 사용해 이미지를 분석하고 설명을 생성하는 함수
    - 기존 predict() 함수에서 이미지를 분석하는 부분을 추출하여 독립적으로 실행 가능하게 만듦
    """
    torch.cuda.empty_cache()

    # 모델 입력 준비
    messages = [
        {"role": "user", "content": [
            {"type": "image"},
            {"type": "text", "text": """
            You are a professional fashion expert, and your task is to analyze the clothing in the given image with **high precision and detail**.

            ### **Instructions**
            - Identify the **type of clothing** and provide an appropriate name for it.
            - Provide a **detailed and structured description** of the clothing, ensuring all relevant attributes are included.
            - Your response must be written as **a single well-formed paragraph** with **exactly 5 sentences**.
            - Do **not** return JSON or bullet points—write a **natural and detailed description** in paragraph form.

            ### **What to Include in Your Response**
            Your description should **naturally** incorporate the following details:
            - **Clothing Type:** Clearly state the **category** or **type of clothing** based on its style and structure.
            - **Gender Suitability:** Indicate whether this clothing is primarily for **men, women, unisex, or unknown**.
            - **Season Suitability:** Mention whether this clothing is best suited for **Spring (SS), Fall/Winter (FW), Summer, Winter, or All Seasons**.
            - **Color:** Describe the **dominant color(s)** visible in the image.
            - **Material:** Identify the **fabric or material composition** if recognizable.
            - **Extra Features:** Include **notable design elements** such as **zippers, buttons, pockets, patterns, embroidery, oversized fit, layering style, or insulation**.
            - **Fit and Silhouette:** Describe whether the clothing is **tight-fitting, slim, regular, oversized, loose, cropped, etc.**
            - **Functionality:** Mention if the clothing is **casual, formal, sportswear, outerwear, loungewear, or multipurpose**.

            ### **Response Formatting**
            - Your response must be a **single paragraph** with **exactly 10 well-formed sentences**.
            - **Do NOT return JSON or bullet points.**
            - **Use a natural and detailed writing style.**

            Your response should sound like a professional fashion expert explaining the clothing in a stylistic and informative manner. Be precise, avoid repetition, and ensure all necessary details are covered.
            """}
        ]}
    ]

    input_text = processor.apply_chat_template(messages, add_generation_prompt=True)
    inputs = processor(image, input_text, add_special_tokens=False, return_tensors="pt").to(device)

    # AI 모델 실행
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=512,
            use_cache=True,
            temperature=0.1,
            eos_token_id=processor.tokenizer.convert_tokens_to_ids('<|eot_id|>'),
        )

    # 결과 변환
    response = processor.decode(outputs[0])
    response = response.split('<|start_header_id|>assistant<|end_header_id|>\n\n')[-1].replace('<|eot_id|>', '')

    print("\n🎯 AI Model Response:\n", response)
    return response

import openai
import json

# ✅ OpenAI API 설정 (최신 API 대응)
client = openai.OpenAI(api_key="OPENAI_API_KEY")  # 🔹 본인의 API 키 사용

def convert_to_json_with_openai(response_text):
    """
    - OpenAI GPT를 사용해 AI 모델 응답을 JSON 형식으로 변환
    - response_text(이미지 분석 결과)를 GPT 모델에 전달하여 JSON 구조 생성
    """
    try:
        prompt = f"""
        You are an AI fashion expert. Analyze the given clothing image description and return a structured JSON response.

        ### **Required JSON Structure**
        {{
            "big_category": "",
            "sub_category": "",
            "gender": "",
            "season": "",
            "color": "",
            "material": "",
            "feature": ""
        }}

        ### **Big Category Choices**
        - 아우터, 상의, 하의, 원피스, 스커트

        ### **Sub Category Choices**
        - 숏패딩, 무스탕, 후드 집업, 레더 재킷, 트러커 재킷, 블레이저 재킷, 카디건,
        아노락 재킷, 플리스, 싱글 코트, 더블 코트, 롱패딩, 발마칸 코트, 롱 슬리브,
        반팔 티, 민소매, 베스트, 반팔 니트, 니트, 맨투맨, 후드티, 셔츠,
        레깅스, 원피스, 미니스커트, 롱스커트, 데님 팬츠, 트레이닝 팬츠,
        치노 팬츠, 슬랙스, 숏 팬츠

        **Other Attributes**
        - **Gender:** 남 / 여 / 유니섹스 / 정보 없음
        - **Season:** SS / FW / 사계절 / 정보 없음
        - **Color:** e.g., 블랙, 화이트, 레드
        - **Material:** e.g., 면, 폴리, 울 (unknown = "")
        - **Feature:** notable elements (e.g., 버튼, 포켓, 지퍼, 프린트)

        ### **Response Guidelines**
        - **Return only a valid JSON object.**
        - **Use Korean values.**
        - **If unknown, return an empty string ("").**

        Here is the clothing description:

        "{response_text}"

        **Now, return only the JSON output, without explanations or additional text.**
        """

        # ✅ 최신 OpenAI API 방식 적용
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        json_response = response.choices[0].message.content.strip()

        print("\n🔍 GPT-4 JSON Response:\n", json_response)

        # ✅ JSON 형식 검증 및 변환
        try:
            parsed_json = json.loads(json_response)
            return parsed_json
        except json.JSONDecodeError:
            print("⚠️ JSON 디코딩 오류 발생! GPT 응답이 올바른 JSON이 아님.")
            return {"error": "Invalid JSON format from OpenAI", "raw_response": json_response}

    except openai.OpenAIError as e:
        print(f"❌ OpenAI API 호출 오류: {str(e)}")
        return {"error": f"OpenAI API 오류: {str(e)}"}

    except Exception as e:
        print(f"❌ 예기치 않은 오류 발생: {str(e)}")
        return {"error": f"Unexpected error: {str(e)}"}

import uvicorn
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from pyngrok import ngrok
import nest_asyncio
import base64
from typing import Optional
import logging

logging.basicConfig(level=logging.INFO)  # INFO 레벨의 로그 출력
logger = logging.getLogger(__name__)


# ✅ Google Colab 환경에서 이벤트 루프 충돌 방지
nest_asyncio.apply()

# ✅ FastAPI 앱 초기화
app = FastAPI()

temp_data_store = {}

# ✅ Pydantic 데이터 모델 정의 (Base64 이미지만 받음)
class ImageUpload(BaseModel):
    image_base64: str  # Base64 인코딩된 이미지

# ✅ 1️⃣ 유사한 옷 검색 (자동 실행)
@app.post("/check_similarity")
def check_similarity(data: ImageUpload):
    """Base64 이미지를 받아서 임베딩 벡터 생성 후, DB에서 유사한 의류 검색"""

    # 1️⃣ Base64 → 이미지 변환
    image = decode_base64_to_image(data.image_base64)
    if image is None:
        raise HTTPException(status_code=400, detail="잘못된 이미지 데이터입니다.")

    # 2️⃣ 이미지 임베딩 벡터 생성
    embedding = get_clip_image_embedding(image)

    # 3️⃣ 기존 의류 데이터와 비교
    similar_doc, similarity_score = find_most_similar_embedding(embedding)

    # ✅ **서버 메모리에 원본 데이터(`ImageUpload` 객체) + 임베딩 벡터 저장**
    temp_data_store["last_checked_image"] = data  # 이미지 데이터 저장
    temp_data_store["last_embedding"] = embedding  # 임베딩 벡터 저장
    temp_data_store["last_checked"] = True  # ✅ 최근 데이터 업로드 여부 확인용

    if similar_doc:
        temp_data_store["last_message"] = "기존과 유사한 의류 발견"
        temp_data_store["existing_clothing_id"] = str(similar_doc["_id"])
        return {
            "message": "기존과 유사한 의류 발견",
            "similarity_score": similarity_score,
            "existing_clothing_id": str(similar_doc["_id"])
        }
    else:
        temp_data_store["last_message"] = "유사한 의류 데이터가 없습니다. 새로 등록해야 합니다."
        temp_data_store["existing_clothing_id"] = "NEW_CLOTHING"
        return {
            "message": "유사한 의류 데이터가 없습니다. 새로 등록해야 합니다.",
            "similarity_score": similarity_score,
            "existing_clothing_id": "NEW_CLOTHING"
        }


# ✅ 2️⃣ 새로운 옷 등록 (AI 모델링 후 저장)
@app.post("/process_last_checked")
def process_last_checked():
    """마지막 확인된 이미지를 사용하여 AI 분석 및 새 의류 등록"""

    if "last_checked_image" not in temp_data_store or "last_embedding" not in temp_data_store:
        raise HTTPException(status_code=404, detail="최근 업로드된 이미지 데이터가 없습니다.")

    # 🔹 저장된 Base64 이미지와 임베딩 벡터 참조
    image_base64 = temp_data_store["last_checked_image"].image_base64
    last_embedding = temp_data_store["last_embedding"]

    # ✅ AI 모델을 사용하여 새 의류 정보 생성
    image = decode_base64_to_image(image_base64)
    generated_text = run_ai_model(image)

    # ✅ GPT를 사용해 JSON 변환
    clothing_json = convert_to_json_with_openai(generated_text)

    # ✅ DB 저장 (Base64 이미지 데이터 + 임베딩 벡터 포함)
    clothing_json["image_base64"] = image_base64  # 🔹 Base64 문자열만 저장
    clothing_json["embedding_vector"] = last_embedding  # 🔹 임베딩 벡터 저장

    new_id = create_new_clothing(clothing_json)

    # ✅ AI 모델이 실행된 후 temp_data_store 초기화
    temp_data_store.clear()

    return {
        "message": "✅ 새로운 옷이 등록되었습니다.",
        "doc_id": new_id
    }

@app.get("/get_last_check")
def get_last_check():
    """최근 `check_similarity` 호출 결과 반환 (Gradio가 주기적으로 확인)"""
    return {
        "message": temp_data_store.get("last_message", "❌ 최근 분석된 이미지 없음"),
        "existing_clothing_id": temp_data_store.get("existing_clothing_id", None),
        "last_checked": temp_data_store.get("last_checked", False)  # ✅ 추가된 값
    }

@app.get("/get_clothing_info/{doc_id}")
def get_clothing_info(doc_id: str):
    """
    - `doc_id`를 받아 해당 의류 정보를 조회
    - ObjectId를 문자열로 변환하여 반환
    """
    clothing_data = read_clothing_item(doc_id)

    if "error" in clothing_data:
        raise HTTPException(status_code=404, detail=clothing_data["error"])

    temp_data_store.clear()

    return clothing_data

@app.delete("/delete_clothing/{doc_id}")
def delete_clothing(doc_id: str):
    """
    - 특정 `doc_id`의 의류 데이터를 삭제하는 API
    """
    return delete_clothing_item(doc_id)

@app.put("/update_clothing_info/{doc_id}")
def update_clothing_info(doc_id: str, update_data: dict):
    """
    - `doc_id`를 받아 해당 의류 정보를 업데이트
    - `count` 필드 증가 및 `updated_at` 수정
    """
    update_result = update_clothing_item(doc_id, update_data)
    if "error" in update_result:
        raise HTTPException(status_code=400, detail=update_result["error"])
    return update_result

@app.get("/get_all_clothing")
def get_all_clothing():
    """DB에서 모든 옷 정보를 가져오는 API"""
    all_clothes = list(clothes_col.find().limit(50))  # 최대 9개만 가져오기

    formatted_clothes = []
    for item in all_clothes:
        item["_id"] = str(item["_id"])  # ObjectId를 문자열로 변환
        item.pop("embedding_vector", None)  # ✅ 필요 없으면 임베딩 벡터 제외 (크기 문제 방지)

        # ✅ Base64 문자열을 클라이언트에서 사용할 수 있도록 직접 변환
        if "image_base64" in item and isinstance(item["image_base64"], bytes):
            item["image_base64"] = base64.b64encode(item["image_base64"]).decode("utf-8")

        formatted_clothes.append(item)

    return {"clothes": formatted_clothes}


# ✅ ngrok을 사용하여 외부에서 접속 가능하도록 설정
ngrok_tunnel = ngrok.connect(8000)
print(f"🔗 FastAPI Public URL: {ngrok_tunnel.public_url}")

# ✅ FastAPI 실행
uvicorn.run(app, host="0.0.0.0", port=8000)