# -*- coding: utf-8 -*-
"""otpensource_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14glPthiXvqNdq8pXLMkDcfkX1kXB1Y3o
"""

# ğŸ“Œ 1ï¸âƒ£ MongoDB ì—°ê²° ë° ê¸°ë³¸ ì„¤ì •
import datetime
import numpy as np
import torch
from pymongo import MongoClient
from bson import ObjectId
from sklearn.metrics.pairwise import cosine_similarity
from PIL import Image
from io import BytesIO
import base64

# âœ… MongoDB Atlas ì—°ê²°
MONGO_URI = "MONGO_URI"
client = MongoClient(MONGO_URI)
db = client["otpensource"]
clothes_col = db["clothes"]

# âœ… Base64 â†’ PIL ì´ë¯¸ì§€ ë³€í™˜ í•¨ìˆ˜
def decode_base64_to_image(image_base64: str):
    """Base64 ë¬¸ìì—´ì„ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
    try:
        image_data = base64.b64decode(image_base64)
        image = Image.open(BytesIO(image_data)).convert("RGB")
        return image
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë””ì½”ë”© ì˜¤ë¥˜: {e}")
        return None

print("âœ… MongoDB ë° Base64 ì´ë¯¸ì§€ ì²˜ë¦¬ ì„¤ì • ì™„ë£Œ!")

import torch
from transformers import CLIPModel, CLIPProcessor

# âœ… CLIP ëª¨ë¸ ì„¤ì •
model_name = "openai/clip-vit-base-patch32"
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"[INFO] Loading CLIP model: {model_name} on device={device}")

clip_model = CLIPModel.from_pretrained(model_name).to(device)
clip_processor = CLIPProcessor.from_pretrained(model_name)

# âœ… PIL ì´ë¯¸ì§€ë¥¼ CLIP ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
def get_clip_image_embedding(image: Image.Image):
    """PIL ì´ë¯¸ì§€ë¥¼ CLIP ëª¨ë¸ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
    try:
        inputs = clip_processor(images=image, return_tensors="pt").to(device)
        with torch.no_grad():
            outputs = clip_model.get_image_features(**inputs)
        embedding = outputs[0].cpu().numpy()
        return embedding.tolist()  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜
    except Exception as e:
        print(f"âŒ CLIP ì„ë² ë”© ì˜¤ë¥˜: {e}")
        return None

print("âœ… CLIP ëª¨ë¸ ë° ì„ë² ë”© í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ!")

# âœ… ê¸°ì¡´ ì˜ë¥˜ ë°ì´í„°ì™€ ë¹„êµ (Cosine Similarity)
def find_most_similar_embedding(new_embedding, threshold=0.9):
    """
    ìƒˆë¡œìš´ ì´ë¯¸ì§€ ì„ë² ë”©ê³¼ DBì˜ ê¸°ì¡´ ë°ì´í„° ë¹„êµí•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ í•­ëª© ì°¾ê¸°
    - threshold ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ê²½ìš° í•´ë‹¹ ë¬¸ì„œ ë°˜í™˜
    - ì—†ì„ ê²½ìš° None ë°˜í™˜
    """
    try:
        # DBì—ì„œ ì €ì¥ëœ ëª¨ë“  ì˜ë¥˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        docs = list(clothes_col.find({"embedding_vector": {"$exists": True, "$ne": None}}))

        if not docs:
            return None, 0.0  # ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°

        embedding_list = [np.array(doc["embedding_vector"], dtype=np.float32) for doc in docs]
        embedding_matrix = np.stack(embedding_list, axis=0)

        new_emb = np.array(new_embedding, dtype=np.float32).reshape(1, -1)
        sim_scores = cosine_similarity(new_emb, embedding_matrix)[0]

        # ê°€ì¥ ìœ ì‚¬í•œ ë°ì´í„° ì°¾ê¸°
        max_idx = np.argmax(sim_scores)
        max_sim = float(sim_scores[max_idx])
        best_doc = docs[max_idx]

        return (best_doc, max_sim) if max_sim >= threshold else (None, max_sim)

    except Exception as e:
        print(f"âŒ ìœ ì‚¬ë„ ë¹„êµ ì˜¤ë¥˜: {e}")
        return None, 0.0

print("âœ… ìœ ì‚¬ë„ ë¹„êµ í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ!")

# âœ… ìƒˆë¡œìš´ ì˜ë¥˜ ë°ì´í„° ì €ì¥
def create_new_clothing(item_data):
    """
    ìƒˆë¡œìš´ ì˜ë¥˜ ë°ì´í„°ë¥¼ MongoDBì— ì €ì¥
    - ìƒì„± ë‚ ì§œ ë° ì—…ë°ì´íŠ¸ ë‚ ì§œ ì¶”ê°€
    - ì°©ìš© íšŸìˆ˜(count) ì´ˆê¸°ê°’ 1 ì„¤ì •
    """
    try:
        now = datetime.datetime.now(datetime.timezone.utc)
        item_data["created_at"] = now
        item_data["updated_at"] = now
        item_data["count"] = 1  # ì°©ìš© íšŸìˆ˜ ì´ˆê¸°ê°’ ì„¤ì •

        result = clothes_col.insert_one(item_data)
        return str(result.inserted_id)

    except Exception as e:
        print(f"âŒ ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {e}")
        return None


# âœ… ê¸°ì¡´ ì˜ë¥˜ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³ , í•„ìš”í•˜ë©´ ì—…ë°ì´íŠ¸ ìˆ˜í–‰
def read_clothing_item(doc_id: str):
    """
    - `doc_id`ë¥¼ ë°›ì•„ í•´ë‹¹ ì˜ë¥˜ ë°ì´í„°ë¥¼ ì¡°íšŒ (ì—…ë°ì´íŠ¸ X)
    - ObjectId â†’ ë¬¸ìì—´ ë³€í™˜ í›„ ë°˜í™˜
    """
    try:
        existing_doc = clothes_col.find_one({"_id": ObjectId(doc_id)})

        if not existing_doc:
            return {"error": "í•´ë‹¹ IDì˜ ì˜ë¥˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        existing_doc["_id"] = str(existing_doc["_id"])  # ObjectId â†’ ë¬¸ìì—´ ë³€í™˜
        return existing_doc  # ì¡°íšŒëœ ë°ì´í„° ë°˜í™˜

    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}


def update_clothing_item(doc_id: str, update_data: dict):
    """
    - `doc_id`ë¥¼ ë°›ì•„ í•´ë‹¹ ì˜ë¥˜ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸
    - `count` í•„ë“œë¥¼ ì¦ê°€ì‹œí‚¤ê³ , `updated_at` ë³€ê²½
    """
    try:
        existing_doc = clothes_col.find_one({"_id": ObjectId(doc_id)})

        if not existing_doc:
            return {"error": "í•´ë‹¹ IDì˜ ì˜ë¥˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        new_count = existing_doc.get("count", 0) + 1  # ì°©ìš© íšŸìˆ˜ ì¦ê°€
        update_data["count"] = new_count
        update_data["updated_at"] = datetime.datetime.now(datetime.timezone.utc)

        clothes_col.update_one({"_id": ObjectId(doc_id)}, {"$set": update_data})

        return {"message": "ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.", "doc_id": doc_id, "updated_data": update_data}

    except Exception as e:
        print(f"âŒ ë°ì´í„° ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}


def delete_clothing_item(doc_id: str):
    """
    - `doc_id`ë¥¼ ë°›ì•„ í•´ë‹¹ ì˜ë¥˜ ë°ì´í„°ë¥¼ ì‚­ì œ
    - ì‚­ì œ ì„±ê³µ ì—¬ë¶€ë¥¼ ë°˜í™˜
    """
    try:
        # ë¨¼ì € ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        existing_doc = clothes_col.find_one({"_id": ObjectId(doc_id)})

        if not existing_doc:
            return {"error": "í•´ë‹¹ IDì˜ ì˜ë¥˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # ë°ì´í„° ì‚­ì œ ìˆ˜í–‰
        clothes_col.delete_one({"_id": ObjectId(doc_id)})

        return {"message": "ì˜ë¥˜ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.", "doc_id": doc_id}

    except Exception as e:
        print(f"âŒ ë°ì´í„° ì‚­ì œ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}


print("âœ… ì˜ë¥˜ ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ!")

import torch
from transformers import AutoProcessor, MllamaForConditionalGeneration

# Determine the device (GPU if available, else CPU)
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load the model and processor
model_name = """hateslopacademy/otpensource-vision-lora"""
model = MllamaForConditionalGeneration.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map='cuda:0'
)

# Move the model to the appropriate device (GPU if available)
model.to(device)
processor = AutoProcessor.from_pretrained("hateslopacademy/otpensource-vision")
# VRAMì„ ë§ì´ ë¨¹ì„ ê²½ìš° ì•„ë˜ ì½”ë“œ ì‹¤í–‰
# model.eval()

def run_ai_model(image):
    """
    - AI ëª¨ë¸ì„ ì‚¬ìš©í•´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    - ê¸°ì¡´ predict() í•¨ìˆ˜ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ë¶€ë¶„ì„ ì¶”ì¶œí•˜ì—¬ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦
    """
    torch.cuda.empty_cache()

    # ëª¨ë¸ ì…ë ¥ ì¤€ë¹„
    messages = [
        {"role": "user", "content": [
            {"type": "image"},
            {"type": "text", "text": """
            You are a professional fashion expert, and your task is to analyze the clothing in the given image with **high precision and detail**.

            ### **Instructions**
            - Identify the **type of clothing** and provide an appropriate name for it.
            - Provide a **detailed and structured description** of the clothing, ensuring all relevant attributes are included.
            - Your response must be written as **a single well-formed paragraph** with **exactly 5 sentences**.
            - Do **not** return JSON or bullet pointsâ€”write a **natural and detailed description** in paragraph form.

            ### **What to Include in Your Response**
            Your description should **naturally** incorporate the following details:
            - **Clothing Type:** Clearly state the **category** or **type of clothing** based on its style and structure.
            - **Gender Suitability:** Indicate whether this clothing is primarily for **men, women, unisex, or unknown**.
            - **Season Suitability:** Mention whether this clothing is best suited for **Spring (SS), Fall/Winter (FW), Summer, Winter, or All Seasons**.
            - **Color:** Describe the **dominant color(s)** visible in the image.
            - **Material:** Identify the **fabric or material composition** if recognizable.
            - **Extra Features:** Include **notable design elements** such as **zippers, buttons, pockets, patterns, embroidery, oversized fit, layering style, or insulation**.
            - **Fit and Silhouette:** Describe whether the clothing is **tight-fitting, slim, regular, oversized, loose, cropped, etc.**
            - **Functionality:** Mention if the clothing is **casual, formal, sportswear, outerwear, loungewear, or multipurpose**.

            ### **Response Formatting**
            - Your response must be a **single paragraph** with **exactly 10 well-formed sentences**.
            - **Do NOT return JSON or bullet points.**
            - **Use a natural and detailed writing style.**

            Your response should sound like a professional fashion expert explaining the clothing in a stylistic and informative manner. Be precise, avoid repetition, and ensure all necessary details are covered.
            """}
        ]}
    ]

    input_text = processor.apply_chat_template(messages, add_generation_prompt=True)
    inputs = processor(image, input_text, add_special_tokens=False, return_tensors="pt").to(device)

    # AI ëª¨ë¸ ì‹¤í–‰
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=512,
            use_cache=True,
            temperature=0.1,
            eos_token_id=processor.tokenizer.convert_tokens_to_ids('<|eot_id|>'),
        )

    # ê²°ê³¼ ë³€í™˜
    response = processor.decode(outputs[0])
    response = response.split('<|start_header_id|>assistant<|end_header_id|>\n\n')[-1].replace('<|eot_id|>', '')

    print("\nğŸ¯ AI Model Response:\n", response)
    return response

import openai
import json

# âœ… OpenAI API ì„¤ì • (ìµœì‹  API ëŒ€ì‘)
client = openai.OpenAI(api_key="OPENAI_API_KEY")  # ğŸ”¹ ë³¸ì¸ì˜ API í‚¤ ì‚¬ìš©

def convert_to_json_with_openai(response_text):
    """
    - OpenAI GPTë¥¼ ì‚¬ìš©í•´ AI ëª¨ë¸ ì‘ë‹µì„ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    - response_text(ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼)ë¥¼ GPT ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ JSON êµ¬ì¡° ìƒì„±
    """
    try:
        prompt = f"""
        You are an AI fashion expert. Analyze the given clothing image description and return a structured JSON response.

        ### **Required JSON Structure**
        {{
            "big_category": "",
            "sub_category": "",
            "gender": "",
            "season": "",
            "color": "",
            "material": "",
            "feature": ""
        }}

        ### **Big Category Choices**
        - ì•„ìš°í„°, ìƒì˜, í•˜ì˜, ì›í”¼ìŠ¤, ìŠ¤ì»¤íŠ¸

        ### **Sub Category Choices**
        - ìˆíŒ¨ë”©, ë¬´ìŠ¤íƒ•, í›„ë“œ ì§‘ì—…, ë ˆë” ì¬í‚·, íŠ¸ëŸ¬ì»¤ ì¬í‚·, ë¸”ë ˆì´ì € ì¬í‚·, ì¹´ë””ê±´,
        ì•„ë…¸ë½ ì¬í‚·, í”Œë¦¬ìŠ¤, ì‹±ê¸€ ì½”íŠ¸, ë”ë¸” ì½”íŠ¸, ë¡±íŒ¨ë”©, ë°œë§ˆì¹¸ ì½”íŠ¸, ë¡± ìŠ¬ë¦¬ë¸Œ,
        ë°˜íŒ” í‹°, ë¯¼ì†Œë§¤, ë² ìŠ¤íŠ¸, ë°˜íŒ” ë‹ˆíŠ¸, ë‹ˆíŠ¸, ë§¨íˆ¬ë§¨, í›„ë“œí‹°, ì…”ì¸ ,
        ë ˆê¹…ìŠ¤, ì›í”¼ìŠ¤, ë¯¸ë‹ˆìŠ¤ì»¤íŠ¸, ë¡±ìŠ¤ì»¤íŠ¸, ë°ë‹˜ íŒ¬ì¸ , íŠ¸ë ˆì´ë‹ íŒ¬ì¸ ,
        ì¹˜ë…¸ íŒ¬ì¸ , ìŠ¬ë™ìŠ¤, ìˆ íŒ¬ì¸ 

        **Other Attributes**
        - **Gender:** ë‚¨ / ì—¬ / ìœ ë‹ˆì„¹ìŠ¤ / ì •ë³´ ì—†ìŒ
        - **Season:** SS / FW / ì‚¬ê³„ì ˆ / ì •ë³´ ì—†ìŒ
        - **Color:** e.g., ë¸”ë™, í™”ì´íŠ¸, ë ˆë“œ
        - **Material:** e.g., ë©´, í´ë¦¬, ìš¸ (unknown = "")
        - **Feature:** notable elements (e.g., ë²„íŠ¼, í¬ì¼“, ì§€í¼, í”„ë¦°íŠ¸)

        ### **Response Guidelines**
        - **Return only a valid JSON object.**
        - **Use Korean values.**
        - **If unknown, return an empty string ("").**

        Here is the clothing description:

        "{response_text}"

        **Now, return only the JSON output, without explanations or additional text.**
        """

        # âœ… ìµœì‹  OpenAI API ë°©ì‹ ì ìš©
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        json_response = response.choices[0].message.content.strip()

        print("\nğŸ” GPT-4 JSON Response:\n", json_response)

        # âœ… JSON í˜•ì‹ ê²€ì¦ ë° ë³€í™˜
        try:
            parsed_json = json.loads(json_response)
            return parsed_json
        except json.JSONDecodeError:
            print("âš ï¸ JSON ë””ì½”ë”© ì˜¤ë¥˜ ë°œìƒ! GPT ì‘ë‹µì´ ì˜¬ë°”ë¥¸ JSONì´ ì•„ë‹˜.")
            return {"error": "Invalid JSON format from OpenAI", "raw_response": json_response}

    except openai.OpenAIError as e:
        print(f"âŒ OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
        return {"error": f"OpenAI API ì˜¤ë¥˜: {str(e)}"}

    except Exception as e:
        print(f"âŒ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {"error": f"Unexpected error: {str(e)}"}

import uvicorn
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from pyngrok import ngrok
import nest_asyncio
import base64
from typing import Optional
import logging

logging.basicConfig(level=logging.INFO)  # INFO ë ˆë²¨ì˜ ë¡œê·¸ ì¶œë ¥
logger = logging.getLogger(__name__)


# âœ… Google Colab í™˜ê²½ì—ì„œ ì´ë²¤íŠ¸ ë£¨í”„ ì¶©ëŒ ë°©ì§€
nest_asyncio.apply()

# âœ… FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

temp_data_store = {}

# âœ… Pydantic ë°ì´í„° ëª¨ë¸ ì •ì˜ (Base64 ì´ë¯¸ì§€ë§Œ ë°›ìŒ)
class ImageUpload(BaseModel):
    image_base64: str  # Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€

# âœ… 1ï¸âƒ£ ìœ ì‚¬í•œ ì˜· ê²€ìƒ‰ (ìë™ ì‹¤í–‰)
@app.post("/check_similarity")
def check_similarity(data: ImageUpload):
    """Base64 ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì„œ ì„ë² ë”© ë²¡í„° ìƒì„± í›„, DBì—ì„œ ìœ ì‚¬í•œ ì˜ë¥˜ ê²€ìƒ‰"""

    # 1ï¸âƒ£ Base64 â†’ ì´ë¯¸ì§€ ë³€í™˜
    image = decode_base64_to_image(data.image_base64)
    if image is None:
        raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ì´ë¯¸ì§€ ë°ì´í„°ì…ë‹ˆë‹¤.")

    # 2ï¸âƒ£ ì´ë¯¸ì§€ ì„ë² ë”© ë²¡í„° ìƒì„±
    embedding = get_clip_image_embedding(image)

    # 3ï¸âƒ£ ê¸°ì¡´ ì˜ë¥˜ ë°ì´í„°ì™€ ë¹„êµ
    similar_doc, similarity_score = find_most_similar_embedding(embedding)

    # âœ… **ì„œë²„ ë©”ëª¨ë¦¬ì— ì›ë³¸ ë°ì´í„°(`ImageUpload` ê°ì²´) + ì„ë² ë”© ë²¡í„° ì €ì¥**
    temp_data_store["last_checked_image"] = data  # ì´ë¯¸ì§€ ë°ì´í„° ì €ì¥
    temp_data_store["last_embedding"] = embedding  # ì„ë² ë”© ë²¡í„° ì €ì¥
    temp_data_store["last_checked"] = True  # âœ… ìµœê·¼ ë°ì´í„° ì—…ë¡œë“œ ì—¬ë¶€ í™•ì¸ìš©

    if similar_doc:
        temp_data_store["last_message"] = "ê¸°ì¡´ê³¼ ìœ ì‚¬í•œ ì˜ë¥˜ ë°œê²¬"
        temp_data_store["existing_clothing_id"] = str(similar_doc["_id"])
        return {
            "message": "ê¸°ì¡´ê³¼ ìœ ì‚¬í•œ ì˜ë¥˜ ë°œê²¬",
            "similarity_score": similarity_score,
            "existing_clothing_id": str(similar_doc["_id"])
        }
    else:
        temp_data_store["last_message"] = "ìœ ì‚¬í•œ ì˜ë¥˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ë“±ë¡í•´ì•¼ í•©ë‹ˆë‹¤."
        temp_data_store["existing_clothing_id"] = "NEW_CLOTHING"
        return {
            "message": "ìœ ì‚¬í•œ ì˜ë¥˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ë“±ë¡í•´ì•¼ í•©ë‹ˆë‹¤.",
            "similarity_score": similarity_score,
            "existing_clothing_id": "NEW_CLOTHING"
        }


# âœ… 2ï¸âƒ£ ìƒˆë¡œìš´ ì˜· ë“±ë¡ (AI ëª¨ë¸ë§ í›„ ì €ì¥)
@app.post("/process_last_checked")
def process_last_checked():
    """ë§ˆì§€ë§‰ í™•ì¸ëœ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ AI ë¶„ì„ ë° ìƒˆ ì˜ë¥˜ ë“±ë¡"""

    if "last_checked_image" not in temp_data_store or "last_embedding" not in temp_data_store:
        raise HTTPException(status_code=404, detail="ìµœê·¼ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ğŸ”¹ ì €ì¥ëœ Base64 ì´ë¯¸ì§€ì™€ ì„ë² ë”© ë²¡í„° ì°¸ì¡°
    image_base64 = temp_data_store["last_checked_image"].image_base64
    last_embedding = temp_data_store["last_embedding"]

    # âœ… AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆ ì˜ë¥˜ ì •ë³´ ìƒì„±
    image = decode_base64_to_image(image_base64)
    generated_text = run_ai_model(image)

    # âœ… GPTë¥¼ ì‚¬ìš©í•´ JSON ë³€í™˜
    clothing_json = convert_to_json_with_openai(generated_text)

    # âœ… DB ì €ì¥ (Base64 ì´ë¯¸ì§€ ë°ì´í„° + ì„ë² ë”© ë²¡í„° í¬í•¨)
    clothing_json["image_base64"] = image_base64  # ğŸ”¹ Base64 ë¬¸ìì—´ë§Œ ì €ì¥
    clothing_json["embedding_vector"] = last_embedding  # ğŸ”¹ ì„ë² ë”© ë²¡í„° ì €ì¥

    new_id = create_new_clothing(clothing_json)

    # âœ… AI ëª¨ë¸ì´ ì‹¤í–‰ëœ í›„ temp_data_store ì´ˆê¸°í™”
    temp_data_store.clear()

    return {
        "message": "âœ… ìƒˆë¡œìš´ ì˜·ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "doc_id": new_id
    }

@app.get("/get_last_check")
def get_last_check():
    """ìµœê·¼ `check_similarity` í˜¸ì¶œ ê²°ê³¼ ë°˜í™˜ (Gradioê°€ ì£¼ê¸°ì ìœ¼ë¡œ í™•ì¸)"""
    return {
        "message": temp_data_store.get("last_message", "âŒ ìµœê·¼ ë¶„ì„ëœ ì´ë¯¸ì§€ ì—†ìŒ"),
        "existing_clothing_id": temp_data_store.get("existing_clothing_id", None),
        "last_checked": temp_data_store.get("last_checked", False)  # âœ… ì¶”ê°€ëœ ê°’
    }

@app.get("/get_clothing_info/{doc_id}")
def get_clothing_info(doc_id: str):
    """
    - `doc_id`ë¥¼ ë°›ì•„ í•´ë‹¹ ì˜ë¥˜ ì •ë³´ë¥¼ ì¡°íšŒ
    - ObjectIdë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
    """
    clothing_data = read_clothing_item(doc_id)

    if "error" in clothing_data:
        raise HTTPException(status_code=404, detail=clothing_data["error"])

    temp_data_store.clear()

    return clothing_data

@app.delete("/delete_clothing/{doc_id}")
def delete_clothing(doc_id: str):
    """
    - íŠ¹ì • `doc_id`ì˜ ì˜ë¥˜ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ëŠ” API
    """
    return delete_clothing_item(doc_id)

@app.put("/update_clothing_info/{doc_id}")
def update_clothing_info(doc_id: str, update_data: dict):
    """
    - `doc_id`ë¥¼ ë°›ì•„ í•´ë‹¹ ì˜ë¥˜ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸
    - `count` í•„ë“œ ì¦ê°€ ë° `updated_at` ìˆ˜ì •
    """
    update_result = update_clothing_item(doc_id, update_data)
    if "error" in update_result:
        raise HTTPException(status_code=400, detail=update_result["error"])
    return update_result

@app.get("/get_all_clothing")
def get_all_clothing():
    """DBì—ì„œ ëª¨ë“  ì˜· ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” API"""
    all_clothes = list(clothes_col.find().limit(50))  # ìµœëŒ€ 9ê°œë§Œ ê°€ì ¸ì˜¤ê¸°

    formatted_clothes = []
    for item in all_clothes:
        item["_id"] = str(item["_id"])  # ObjectIdë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        item.pop("embedding_vector", None)  # âœ… í•„ìš” ì—†ìœ¼ë©´ ì„ë² ë”© ë²¡í„° ì œì™¸ (í¬ê¸° ë¬¸ì œ ë°©ì§€)

        # âœ… Base64 ë¬¸ìì—´ì„ í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì§ì ‘ ë³€í™˜
        if "image_base64" in item and isinstance(item["image_base64"], bytes):
            item["image_base64"] = base64.b64encode(item["image_base64"]).decode("utf-8")

        formatted_clothes.append(item)

    return {"clothes": formatted_clothes}


# âœ… ngrokì„ ì‚¬ìš©í•˜ì—¬ ì™¸ë¶€ì—ì„œ ì ‘ì† ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
ngrok_tunnel = ngrok.connect(8000)
print(f"ğŸ”— FastAPI Public URL: {ngrok_tunnel.public_url}")

# âœ… FastAPI ì‹¤í–‰
uvicorn.run(app, host="0.0.0.0", port=8000)