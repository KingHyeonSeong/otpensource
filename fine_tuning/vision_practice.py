# -*- coding: utf-8 -*-
"""vision_practice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uiy-oXDez9ClBZiIXDIT3TH25N5CXMQu
"""



import os
from unsloth import FastVisionModel
import torch
from datasets import load_dataset
from transformers import TextStreamer
from unsloth import is_bf16_supported
from unsloth.trainer import UnslothVisionDataCollator
from trl import SFTTrainer, SFTConfig

# 1. Load the model

model, tokenizer = FastVisionModel.from_pretrained(
    "Bllossom/llama-3.2-Korean-Bllossom-AICA-5B",
    load_in_4bit = True,
    use_gradient_checkpointing = "unsloth",
)

model = FastVisionModel.get_peft_model(
    model,
    finetune_vision_layers     = True,
    finetune_language_layers   = True,
    finetune_attention_modules = True,
    finetune_mlp_modules      = True,
    r = 16,
    lora_alpha = 16,
    lora_dropout = 0,
    bias = "none",
    random_state = 3407,
    use_rslora = False,
    loftq_config = None,
)



# 2. Load the dataset

pre_dataset = load_dataset('hateslopacademy/otpensource_dataset', split='train')

import json

def transform_data(data):
    """
    주어진 데이터를 'output', 'instruction', 'image_url'로 변환.
    - instruction: "이 옷은 어떤 옷인지 정보를 알려주세요"
    - output: big_category와 product_name을 제외한 나머지 정보를 JSON 형식으로 저장
    - image_url: 기존 image_url 값 유지
    """
    # 변환 작업
    output_data = {
        ("category" if key == "sub_category" else key): value
        for key, value in data.items()
        if key not in ["big_category", "product_name", "image_url"]
    }

    transformed = {
        "instruction" : """
당신은 JSON 형식 데이터를 작성하는 전문 AI입니다. 아래 제공된 옷에 대한 정보를 기반으로, JSON 형식으로만 응답하세요. 출력 형식은 반드시 아래의 템플릿을 따라야 합니다.


### 출력 형식 ###
{
    "category": "옷 종류 (예: 민소매 티셔츠, 청바지, 후드)",
    "gender": "착용자 성별 (예: 남, 여, 정보 없음)",
    "season": "계절 정보 (예: SS, FW, 사계절, 정보 없음)",
    "color": "색상 (예: 화이트, 블랙)",
    "material": "소재 (예: 울, 폴리, 정보 없음)",
    "feature": "특징 (쉼표로 구분된 문자열, 예: 슬리브리스, 반팔, 긴팔)"
}

### 입력 이미지 ###
[아래에 제공된 이미지를 분석하고 JSON 데이터를 생성하세요.]
"""
,
        "output": json.dumps(output_data, ensure_ascii=False),  # JSON 형식으로 저장
        "image_url": data["image_url"]
    }

    return transformed

# 데이터셋 변환
transformed_data = pre_dataset.map(transform_data)

# 변환된 데이터셋 저장
train_dataset = transformed_data

# 확인 출력
train_dataset[0]

from PIL import Image
import requests
from io import BytesIO
from tqdm import tqdm

def convert_to_conversation(sample):
    try:
        # URL에서 이미지 다운로드
        url = sample.get('image_url', None)  # 이미지 URL 가져오기
        if not url:
            print("이미지 URL 없음")
            return None

        res = requests.get(url, stream=True, timeout=10)
        if res.status_code == 200:
            image = Image.open(res.raw)
        else:
            print(f"이미지 다운로드 실패: HTTP {res.status_code}")
            return None

    except Exception as e:
        print(f"이미지 처리 실패: {e}")
        return None

    try:
        # conversation 형식 변환
        conversation = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": sample['instruction']},
                    {"type": "image", "image": image}
                ]
            },
            {
                "role": "assistant",
                "content": [
                    {"type": "text", "text": sample["output"]}
                ]
            },
        ]
        return {"messages": conversation}
    except Exception as e:
        print(f"데이터 처리 실패: {e}")
        return None

# 데이터셋 변환
converted_dataset = [
    convert_to_conversation(sample) for sample in tqdm(train_dataset, desc="Processing Dataset") if sample is not None
]
converted_dataset = [data for data in converted_dataset if data is not None]  # None 값 필터링

len(converted_dataset)

# 3. Before training

FastVisionModel.for_inference(model)
image_url = "https://image.msscdn.net/thumbnails/images/goods_img/20241029/4568758/4568758_17301816059577_big.jpg?w=1200"

print(image_url)

res = requests.get(image_url, stream=True, timeout=10)
image = Image.open(res.raw)
instruction = """
당신은 JSON 형식 데이터를 작성하는 전문 AI입니다. 아래 제공된 옷에 대한 정보를 기반으로, JSON 형식으로만 응답하세요. 출력 형식은 반드시 아래의 템플릿을 따라야 합니다.


### 출력 형식 ###
{
    "category": "옷 종류 (예: 민소매 티셔츠, 청바지, 후드)",
    "gender": "착용자 성별 (예: 남, 여, 정보 없음)",
    "season": "계절 정보 (예: SS, FW, 사계절, 정보 없음)",
    "color": "색상 (예: 화이트, 블랙)",
    "material": "소재 (예: 울, 폴리, 정보 없음)",
    "feature": "특징 (쉼표로 구분된 문자열, 예: 슬리브리스, 반팔, 긴팔)"
}

### 입력 이미지 ###
[아래에 제공된 이미지를 분석하고 JSON 데이터를 생성하세요.]
"""

messages = [
    {"role": "user", "content": [
        {"type": "image"},
        {"type": "text", "text": instruction}
    ]}
]
input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)
inputs = tokenizer(
    image,
    input_text,
    add_special_tokens = False,
    return_tensors = "pt",
).to("cuda")

print("\nBefore training:\n")

text_streamer = TextStreamer(tokenizer, skip_prompt = True)
_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,
                   use_cache = True, temperature = 1.5, min_p = 0.1)

# 4. Training

FastVisionModel.for_training(model)

trainer = SFTTrainer(
    model = model,
    tokenizer = tokenizer,
    data_collator = UnslothVisionDataCollator(model, tokenizer),
    train_dataset = converted_dataset,
    args = SFTConfig(
        per_device_train_batch_size = 2,
        gradient_accumulation_steps = 4,
        warmup_steps = 5,
        max_steps = 30,
        learning_rate = 2e-4,
        fp16 = not is_bf16_supported(),
        bf16 = is_bf16_supported(),
        logging_steps = 1,
        optim = "adamw_8bit",
        weight_decay = 0.01,
        lr_scheduler_type = "linear",
        seed = 3407,
        output_dir = "outputs",
        report_to = "none",
        remove_unused_columns = False,
        dataset_text_field = "",
        dataset_kwargs = {"skip_prepare_dataset": True},
        dataset_num_proc = 4,
        max_seq_length = 2048,
    ),
)

gpu_stats = torch.cuda.get_device_properties(0)
start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)
max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)
print(f"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.")
print(f"{start_gpu_memory} GB of memory reserved.")

trainer_stats = trainer.train()

used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)
used_memory_for_lora = round(used_memory - start_gpu_memory, 3)
used_percentage = round(used_memory         /max_memory*100, 3)
lora_percentage = round(used_memory_for_lora/max_memory*100, 3)
print(f"{trainer_stats.metrics['train_runtime']} seconds used for training.")
print(f"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.")
print(f"Peak reserved memory = {used_memory} GB.")
print(f"Peak reserved memory for training = {used_memory_for_lora} GB.")
print(f"Peak reserved memory % of max memory = {used_percentage} %.")
print(f"Peak reserved memory for training % of max memory = {lora_percentage} %.")

# 3. After training

import os
import torch
import requests
from PIL import Image
from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer

# 모델 경로 (로컬에서 불러오기)
MODEL_PATH = "hateslopacademy/otpensource-vision"

# 모델 및 토크나이저 로드 (로컬)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_PATH,
    torch_dtype=torch.bfloat16,
    device_map="cuda"
)

tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)

FastVisionModel.for_inference(model)

image_url = "https://raw.githubusercontent.com/KingHyeonSeong/otpensource/refs/heads/main/KakaoTalk_20250126_151817195_02.jpg"
res = requests.get(image_url, stream=True, timeout=10)
image = Image.open(res.raw)
instruction = """ You are a fashion expert, and your task is to analyze the clothing in the given image.
Select one or two appropriate category from the list below

category list:
Short Puffer/Heavy Outer
Mustang/Fur
Hood Zip-up
Blouson/MA-1
Leather/Riders Jacket
Trucker Jacket
Suit/Blazer Jacket
Cardigan
Anorak Jacket
Fleece/Teddy Jacket
Training Jacket
Stadium Jacket
Transitional Coat
Winter Single Coat
Winter Double Coat
Other Winter Coats
Long Puffer/Heavy Outer
Padded Vest
Vest
Safari/Hunting Jacket
Nylon/Coach Jacket
Knit/Sweater
Sweatshirt
Hoodie
Shirt/Blouse
Piqué/Collar T-shirt
Long-sleeve T-shirt
Short-sleeve T-shirt
Sleeveless T-shirt
Denim Pants
Training/Jogger Pants
Cotton Pants
Suit Pants/Slacks
Short Pants
Leggings
Jumpsuit/Overall
Mini Dress
Midi Dress
Maxi Dress
Mini Skirt
Midi Skirt
Long Skirt


and include detailed and accurate descriptions for the following features: gender, season, color, material, and extra feature.
Be as specific and precise as possible in your response.
and do not repeat your answer

"""

messages = [
    {"role": "user", "content": [
        {"type": "image"},
        {"type": "text", "text": instruction}
    ]}
]
input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)
inputs = tokenizer(
    image,
    input_text,
    add_special_tokens = False,
    return_tensors = "pt",
).to("cuda")

print("\nAfter training:\n")

text_streamer = TextStreamer(tokenizer, skip_prompt = True)
_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,
                   use_cache = True, temperature = 1.5, min_p = 0.1)


from huggingface_hub.hf_api import HfFolder
HfFolder.save_token("my_hf_token")

import os
import glob
import json
from huggingface_hub import upload_file


# 모델 저장 경로 및 이름
MODEL_PATH = "lora_model"
HUGGINGFACE_REPO = "hateslopacademy/otpensource-vision-lora"  # 👉 LoRA 모델 따로 업로드

# ✅ LoRA 모델 및 토크나이저 저장
model.save_pretrained(MODEL_PATH)  # `.safetensors` 형식으로 저장
tokenizer.save_pretrained(MODEL_PATH)

# ✅ `.safetensors.index.json` 자동 생성 확인 및 저장
index_path = os.path.join(MODEL_PATH, "model.safetensors.index.json")

if not os.path.exists(index_path):
    print("⚠️ Warning: model.safetensors.index.json이 없습니다. 생성 중...")
    from safetensors.torch import save_file

    # 저장된 safetensors 파일 찾기
    safetensor_files = glob.glob(os.path.join(MODEL_PATH, "*.safetensors"))

    # 인덱스 파일 생성
    index_data = {
        "metadata": {"format": "safetensors", "dtype": "float16"},
        "weight_map": {f.split("/")[-1]: f for f in safetensor_files},
    }

    # JSON 파일 저장
    with open(index_path, "w") as f:
        json.dump(index_data, f)

    print("✅ model.safetensors.index.json 생성 완료!")

# ✅ model.safetensors.index.json 업로드
upload_file(
    path_or_fileobj=index_path,
    path_in_repo="model.safetensors.index.json",
    repo_id=HUGGINGFACE_REPO,
    token=HF_TOKEN,
)

# ✅ LoRA 모델을 Hugging Face Hub에 업로드
model.push_to_hub(
    HUGGINGFACE_REPO,
    token=HF_TOKEN
)

print(f"✅ LoRA 모델이 {HUGGINGFACE_REPO}에 성공적으로 업로드되었습니다!")