{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz22LYiiU7Fj"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlsgdj2qYl4u"
      },
      "outputs": [],
      "source": [
        "!datasets-cli test hateslopacademy/otpensource_data --save_info --data-files \"*.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY1EPWkYGDfc"
      },
      "outputs": [],
      "source": [
        "!pip install unsloth\n",
<<<<<<< HEAD
        "!export HF_TOKEN=xxxxxxxxxxxxxxxxxxxxxx"
=======
        "!export HF_TOKEN=XXXXXXXXXXXXXXXXXXXXXXXXXX"
>>>>>>> a3aa2ce4799716f28fe91715abaa0bec6037dd1f
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r9Aa5v8GmgW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from unsloth import FastVisionModel\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import TextStreamer\n",
        "from unsloth import is_bf16_supported\n",
        "from unsloth.trainer import UnslothVisionDataCollator\n",
        "from trl import SFTTrainer, SFTConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7ZRlIIkGvYr"
      },
      "outputs": [],
      "source": [
        "# 1. Load the model\n",
        "\n",
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "    \"Bllossom/llama-3.2-Korean-Bllossom-AICA-5B\",\n",
        "    load_in_4bit = True,\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        ")\n",
        "\n",
        "model = FastVisionModel.get_peft_model(\n",
        "    model,\n",
        "    finetune_vision_layers     = True,\n",
        "    finetune_language_layers   = True,\n",
        "    finetune_attention_modules = True,\n",
        "    finetune_mlp_modules      = True,\n",
        "    r = 16,\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gQN8augHCYj"
      },
      "outputs": [],
      "source": [
        "# 2. Load the dataset\n",
        "\n",
        "pre_dataset = load_dataset('hateslopacademy/otpensource_data', split='train')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCYbY2zzHcTq"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def transform_data(data):\n",
        "    \"\"\"\n",
        "    주어진 데이터를 'output', 'instruction', 'image_url'로 변환.\n",
        "    - instruction: \"이 옷은 어떤 옷인지 정보를 알려주세요\"\n",
        "    - output: big_category와 product_name을 제외한 나머지 정보를 JSON 형식으로 저장\n",
        "    - image_url: 기존 image_url 값 유지\n",
        "    \"\"\"\n",
        "    # 변환 작업\n",
        "    output_data = {\n",
        "        (\"category\" if key == \"sub_category\" else key): value\n",
        "        for key, value in data.items()\n",
        "        if key not in [\"big_category\", \"product_name\", \"image_url\"]\n",
        "    }\n",
        "\n",
        "    transformed = {\n",
        "        \"instruction\" : \"\"\"\n",
        "당신은 JSON 형식 데이터를 작성하는 전문 AI입니다. 아래 제공된 옷에 대한 정보를 기반으로, JSON 형식으로만 응답하세요. 출력 형식은 반드시 아래의 템플릿을 따라야 합니다.\n",
        "\n",
        "\n",
        "### 출력 형식 ###\n",
        "{\n",
        "    \"category\": \"옷 종류 (예: 민소매 티셔츠, 청바지, 후드)\",\n",
        "    \"gender\": \"착용자 성별 (예: 남, 여, 정보 없음)\",\n",
        "    \"season\": \"계절 정보 (예: SS, FW, 사계절, 정보 없음)\",\n",
        "    \"color\": \"색상 (예: 화이트, 블랙)\",\n",
        "    \"material\": \"소재 (예: 울, 폴리, 정보 없음)\",\n",
        "    \"feature\": \"특징 (쉼표로 구분된 문자열, 예: 슬리브리스, 반팔, 긴팔)\"\n",
        "}\n",
        "\n",
        "### 입력 이미지 ###\n",
        "[아래에 제공된 이미지를 분석하고 JSON 데이터를 생성하세요.]\n",
        "\"\"\"\n",
        ",\n",
        "        \"output\": json.dumps(output_data, ensure_ascii=False),  # JSON 형식으로 저장\n",
        "        \"image_url\": data[\"image_url\"]\n",
        "    }\n",
        "\n",
        "    return transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvAThM69Hp5z"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 변환\n",
        "transformed_data = pre_dataset.map(transform_data)\n",
        "\n",
        "# 변환된 데이터셋 저장\n",
        "train_dataset = transformed_data\n",
        "\n",
        "# 확인 출력\n",
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9ggBaihH8ey"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "\n",
        "def convert_to_conversation(sample):\n",
        "    try:\n",
        "        # URL에서 이미지 다운로드\n",
        "        url = sample.get('image_url', None)  # 이미지 URL 가져오기\n",
        "        if not url:\n",
        "            print(\"이미지 URL 없음\")\n",
        "            return None\n",
        "\n",
        "        res = requests.get(url, stream=True, timeout=10)\n",
        "        if res.status_code == 200:\n",
        "            image = Image.open(res.raw)\n",
        "        else:\n",
        "            print(f\"이미지 다운로드 실패: HTTP {res.status_code}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"이미지 처리 실패: {e}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # conversation 형식 변환\n",
        "        conversation = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": sample['instruction']},\n",
        "                    {\"type\": \"image\", \"image\": image}\n",
        "                ]\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": sample[\"output\"]}\n",
        "                ]\n",
        "            },\n",
        "        ]\n",
        "        return {\"messages\": conversation}\n",
        "    except Exception as e:\n",
        "        print(f\"데이터 처리 실패: {e}\")\n",
        "        return None\n",
        "\n",
        "# 데이터셋 변환\n",
        "converted_dataset = [\n",
        "    convert_to_conversation(sample) for sample in tqdm(train_dataset, desc=\"Processing Dataset\") if sample is not None\n",
        "]\n",
        "converted_dataset = [data for data in converted_dataset if data is not None]  # None 값 필터링\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrC96-i9KfZ6"
      },
      "outputs": [],
      "source": [
        "len(converted_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8JzjpsbKptj"
      },
      "outputs": [],
      "source": [
        "# 3. Before training\n",
        "\n",
        "FastVisionModel.for_inference(model)\n",
        "image_url = train_dataset[0][\"image_url\"]\n",
        "\n",
        "print(image_url)\n",
        "\n",
        "res = requests.get(image_url, stream=True, timeout=10)\n",
        "image = Image.open(res.raw)\n",
        "instruction = \"\"\"\n",
        "당신은 JSON 형식 데이터를 작성하는 전문 AI입니다. 아래 제공된 옷에 대한 정보를 기반으로, JSON 형식으로만 응답하세요. 출력 형식은 반드시 아래의 템플릿을 따라야 합니다.\n",
        "\n",
        "\n",
        "### 출력 형식 ###\n",
        "{\n",
        "    \"category\": \"옷 종류 (예: 민소매 티셔츠, 청바지, 후드)\",\n",
        "    \"gender\": \"착용자 성별 (예: 남, 여, 정보 없음)\",\n",
        "    \"season\": \"계절 정보 (예: SS, FW, 사계절, 정보 없음)\",\n",
        "    \"color\": \"색상 (예: 화이트, 블랙)\",\n",
        "    \"material\": \"소재 (예: 울, 폴리, 정보 없음)\",\n",
        "    \"feature\": \"특징 (쉼표로 구분된 문자열, 예: 슬리브리스, 반팔, 긴팔)\"\n",
        "}\n",
        "\n",
        "### 입력 이미지 ###\n",
        "[아래에 제공된 이미지를 분석하고 JSON 데이터를 생성하세요.]\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"image\"},\n",
        "        {\"type\": \"text\", \"text\": instruction}\n",
        "    ]}\n",
        "]\n",
        "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
        "inputs = tokenizer(\n",
        "    image,\n",
        "    input_text,\n",
        "    add_special_tokens = False,\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "print(\"\\nBefore training:\\n\")\n",
        "\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UZ30aIILXAA"
      },
      "outputs": [],
      "source": [
        "# 4. Training\n",
        "\n",
        "FastVisionModel.for_training(model)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = UnslothVisionDataCollator(model, tokenizer),\n",
        "    train_dataset = converted_dataset,\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 30,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bf16_supported(),\n",
        "        bf16 = is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\",\n",
        "        remove_unused_columns = False,\n",
        "        dataset_text_field = \"\",\n",
        "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
        "        dataset_num_proc = 4,\n",
        "        max_seq_length = 2048,\n",
        "    ),\n",
        ")\n",
        "\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")\n",
        "\n",
        "trainer_stats = trainer.train()\n",
        "\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1NCWSMcNHIh"
      },
      "outputs": [],
      "source": [
        "# 3. After training\n",
        "\n",
        "FastVisionModel.for_inference(model)\n",
        "image_url = train_dataset[0][\"image_url\"]\n",
        "res = requests.get(image_url, stream=True, timeout=10)\n",
        "image = Image.open(res.raw)\n",
        "instruction = \"\"\"\n",
        "당신은 JSON 형식 데이터를 작성하는 전문 AI입니다. 아래 제공된 옷에 대한 정보를 기반으로, JSON 형식으로만 응답하세요. 출력 형식은 반드시 아래의 템플릿을 따라야 합니다.\n",
        "\n",
        "\n",
        "### 출력 형식 ###\n",
        "{\n",
        "    \"category\": \"옷 종류 (예: 민소매 티셔츠, 청바지, 후드)\",\n",
        "    \"gender\": \"착용자 성별 (예: 남, 여, 정보 없음)\",\n",
        "    \"season\": \"계절 정보 (예: SS, FW, 사계절, 정보 없음)\",\n",
        "    \"color\": \"색상 (예: 화이트, 블랙)\",\n",
        "    \"material\": \"소재 (예: 울, 폴리, 정보 없음)\",\n",
        "    \"feature\": \"특징 (쉼표로 구분된 문자열, 예: 슬리브리스, 반팔, 긴팔)\"\n",
        "}\n",
        "\n",
        "### 입력 이미지 ###\n",
        "[아래에 제공된 이미지를 분석하고 JSON 데이터를 생성하세요.]\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"image\"},\n",
        "        {\"type\": \"text\", \"text\": instruction}\n",
        "    ]}\n",
        "]\n",
        "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
        "inputs = tokenizer(\n",
        "    image,\n",
        "    input_text,\n",
        "    add_special_tokens = False,\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "print(\"\\nAfter training:\\n\")\n",
        "\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_zT-yFtPhfp"
      },
      "outputs": [],
      "source": [
        "# 6. Save the model\n",
        "\n",
        "model.save_pretrained(\"lora_model\")\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "\n",
        "model.save_pretrained_merged(\"hateslopacademy/otpensource-vision\", tokenizer,)\n",
        "model.push_to_hub_merged(\"hateslopacademy/otpensource-vision\", tokenizer, save_method = \"merged_16bit\", token = os.environ.get(\"HF_TOKEN\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
